"""
Agenté…ç½®ç»„ä»¶ V3
åŸºäºui-ux skillçš„ä¼ä¸šçº§è®¾è®¡,ä½¿ç”¨å¡ç‰‡å¸ƒå±€ä¼˜åŒ–UI
"""
import json
import os
import gradio as gr
from gradio.components import Component
from typing import Any, Dict, Optional
from src.webui.webui_manager import WebuiManager
from src.utils import config
import logging
from functools import partial

logger = logging.getLogger(__name__)


def update_model_dropdown(llm_provider):
    """æ›´æ–°æ¨¡å‹åç§°ä¸‹æ‹‰åˆ—è¡¨"""
    if llm_provider in config.model_names:
        return gr.Dropdown(
            choices=config.model_names[llm_provider],
            value=config.model_names[llm_provider][0],
            interactive=True
        )
    else:
        return gr.Dropdown(choices=[], value="", interactive=True, allow_custom_value=True)


async def update_mcp_server(mcp_file: str, webui_manager: WebuiManager):
    """æ›´æ–°MCPæœåŠ¡å™¨é…ç½®"""
    if hasattr(webui_manager, "bu_controller") and webui_manager.bu_controller:
        logger.warning("âš ï¸ Close controller because mcp file has changed!")
        await webui_manager.bu_controller.close_mcp_client()
        webui_manager.bu_controller = None

    if not mcp_file or not os.path.exists(mcp_file) or not mcp_file.endswith('.json'):
        logger.warning(f"{mcp_file} is not a valid MCP file.")
        return None, gr.update(visible=False)

    with open(mcp_file, 'r') as f:
        mcp_server = json.load(f)

    return json.dumps(mcp_server, indent=2), gr.update(visible=True)


def create_agent_settings_tab_v3(webui_manager: WebuiManager):
    """åˆ›å»ºAgenté…ç½®é¡µé¢ - V3ä¼˜åŒ–ç‰ˆ"""
    tab_components = {}

    # === ç³»ç»ŸPrompté…ç½®å¡ç‰‡ ===
    with gr.Group(elem_classes=["card"]):
        gr.Markdown("### ğŸ“ ç³»ç»ŸPrompté…ç½®")
        override_system_prompt = gr.Textbox(
            label="è¦†ç›–ç³»ç»ŸPrompt",
            lines=4,
            placeholder="è¾“å…¥è‡ªå®šä¹‰çš„ç³»ç»Ÿæç¤ºè¯,å°†å®Œå…¨æ›¿æ¢é»˜è®¤æç¤ºè¯...",
            interactive=True
        )
        extend_system_prompt = gr.Textbox(
            label="æ‰©å±•ç³»ç»ŸPrompt",
            lines=4,
            placeholder="è¾“å…¥é¢å¤–çš„æç¤ºè¯,å°†è¿½åŠ åˆ°é»˜è®¤æç¤ºè¯åé¢...",
            interactive=True
        )

    # === MCPæœåŠ¡å™¨é…ç½®å¡ç‰‡ ===
    with gr.Group(elem_classes=["card"]):
        gr.Markdown("### ğŸ”§ MCPæœåŠ¡å™¨é…ç½®")
        mcp_json_file = gr.File(
            label="MCPé…ç½®æ–‡ä»¶",
            interactive=True,
            file_types=[".json"]
        )
        mcp_server_config = gr.Textbox(
            label="MCPæœåŠ¡å™¨é…ç½®",
            lines=6,
            interactive=True,
            visible=False
        )

    # === ä¸»LLMé…ç½®å¡ç‰‡ ===
    with gr.Group(elem_classes=["card"]):
        gr.Markdown("### ğŸ¤– ä¸»LLMé…ç½®")
        
        with gr.Row():
            llm_provider = gr.Dropdown(
                choices=[provider for provider, model in config.model_names.items()],
                label="LLM Provider",
                value=os.getenv("DEFAULT_LLM", "openai"),
                info="é€‰æ‹©LLMæœåŠ¡æä¾›å•†",
                interactive=True
            )
            llm_model_name = gr.Dropdown(
                label="LLM Model",
                choices=config.model_names[os.getenv("DEFAULT_LLM", "openai")],
                value=config.model_names[os.getenv("DEFAULT_LLM", "openai")][0],
                interactive=True,
                allow_custom_value=True,
                info="é€‰æ‹©æ¨¡å‹æˆ–è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°"
            )
        
        with gr.Row():
            llm_temperature = gr.Slider(
                minimum=0.0,
                maximum=2.0,
                value=0.6,
                step=0.1,
                label="Temperature",
                info="æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ (0=ç¡®å®šæ€§, 2=é«˜éšæœºæ€§)",
                interactive=True
            )
            use_vision = gr.Checkbox(
                label="å¯ç”¨Vision",
                value=True,
                info="å°†é«˜äº®æˆªå›¾è¾“å…¥LLMè¿›è¡Œè§†è§‰åˆ†æ",
                interactive=True
            )
            ollama_num_ctx = gr.Slider(
                minimum=2 ** 8,
                maximum=2 ** 16,
                value=16000,
                step=1,
                label="Ollamaä¸Šä¸‹æ–‡é•¿åº¦",
                info="æ§åˆ¶æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦(è¶Šå°è¶Šå¿«)",
                visible=False,
                interactive=True
            )

        with gr.Row():
            llm_base_url = gr.Textbox(
                label="Base URL",
                value="",
                placeholder="https://api.openai.com/v1",
                info="APIç«¯ç‚¹URL(å¯é€‰)"
            )
            llm_api_key = gr.Textbox(
                label="API Key",
                type="password",
                value="",
                placeholder="sk-...",
                info="APIå¯†é’¥(ç•™ç©ºä½¿ç”¨.envé…ç½®)"
            )

    # === Planner LLMé…ç½®å¡ç‰‡ ===
    with gr.Group(elem_classes=["card"]):
        gr.Markdown("### ğŸ¯ Planner LLMé…ç½®")
        gr.Markdown("*å¯é€‰:ä¸ºè§„åˆ’ä»»åŠ¡é…ç½®ç‹¬ç«‹çš„LLMæ¨¡å‹*")
        
        with gr.Row():
            planner_llm_provider = gr.Dropdown(
                choices=[provider for provider, model in config.model_names.items()],
                label="Planner LLM Provider",
                info="é€‰æ‹©è§„åˆ’å™¨LLMæœåŠ¡æä¾›å•†",
                value=None,
                interactive=True
            )
            planner_llm_model_name = gr.Dropdown(
                label="Planner LLM Model",
                interactive=True,
                allow_custom_value=True,
                info="é€‰æ‹©æ¨¡å‹æˆ–è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°"
            )
        
        with gr.Row():
            planner_llm_temperature = gr.Slider(
                minimum=0.0,
                maximum=2.0,
                value=0.6,
                step=0.1,
                label="Temperature",
                info="æ§åˆ¶è§„åˆ’å™¨æ¨¡å‹çš„éšæœºæ€§",
                interactive=True
            )
            planner_use_vision = gr.Checkbox(
                label="å¯ç”¨Vision(Planner)",
                value=False,
                info="ä¸ºè§„åˆ’å™¨å¯ç”¨è§†è§‰åˆ†æ",
                interactive=True
            )
            planner_ollama_num_ctx = gr.Slider(
                minimum=2 ** 8,
                maximum=2 ** 16,
                value=16000,
                step=1,
                label="Ollamaä¸Šä¸‹æ–‡é•¿åº¦",
                info="æ§åˆ¶æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦",
                visible=False,
                interactive=True
            )

        with gr.Row():
            planner_llm_base_url = gr.Textbox(
                label="Base URL",
                value="",
                placeholder="https://api.openai.com/v1",
                info="APIç«¯ç‚¹URL(å¯é€‰)"
            )
            planner_llm_api_key = gr.Textbox(
                label="API Key",
                type="password",
                value="",
                placeholder="sk-...",
                info="APIå¯†é’¥(ç•™ç©ºä½¿ç”¨.envé…ç½®)"
            )

    # === Agentå‚æ•°é…ç½®å¡ç‰‡ ===
    with gr.Group(elem_classes=["card"]):
        gr.Markdown("### âš¡ Agentæ‰§è¡Œå‚æ•°")
        
        with gr.Row():
            max_steps = gr.Slider(
                minimum=1,
                maximum=1000,
                value=30,
                step=1,
                label="æœ€å¤§æ‰§è¡Œæ­¥æ•°",
                info="Agentæ‰§è¡Œçš„æœ€å¤§æ­¥æ•°(æ­¥æ•°ç†”æ–­é˜ˆå€¼)",
                interactive=True
            )
            max_actions = gr.Slider(
                minimum=1,
                maximum=100,
                value=10,
                step=1,
                label="æ¯æ­¥æœ€å¤§åŠ¨ä½œæ•°",
                info="æ¯ä¸ªæ­¥éª¤ä¸­Agentå¯æ‰§è¡Œçš„æœ€å¤§åŠ¨ä½œæ•°",
                interactive=True
            )

        with gr.Row():
            max_input_tokens = gr.Number(
                label="æœ€å¤§è¾“å…¥Tokenæ•°",
                value=128000,
                precision=0,
                info="é™åˆ¶è¾“å…¥Tokenæ•°é‡",
                interactive=True
            )
            tool_calling_method = gr.Dropdown(
                label="å·¥å…·è°ƒç”¨æ–¹æ³•",
                value="auto",
                interactive=True,
                allow_custom_value=True,
                choices=['function_calling', 'json_mode', 'raw', 'auto', 'tools', "None"],
                info="é€‰æ‹©å·¥å…·è°ƒç”¨çš„æ–¹å¼",
                visible=True
            )

    # æ³¨å†Œç»„ä»¶åˆ°manager
    tab_components.update(dict(
        override_system_prompt=override_system_prompt,
        extend_system_prompt=extend_system_prompt,
        llm_provider=llm_provider,
        llm_model_name=llm_model_name,
        llm_temperature=llm_temperature,
        use_vision=use_vision,
        ollama_num_ctx=ollama_num_ctx,
        llm_base_url=llm_base_url,
        llm_api_key=llm_api_key,
        planner_llm_provider=planner_llm_provider,
        planner_llm_model_name=planner_llm_model_name,
        planner_llm_temperature=planner_llm_temperature,
        planner_use_vision=planner_use_vision,
        planner_ollama_num_ctx=planner_ollama_num_ctx,
        planner_llm_base_url=planner_llm_base_url,
        planner_llm_api_key=planner_llm_api_key,
        max_steps=max_steps,
        max_actions=max_actions,
        max_input_tokens=max_input_tokens,
        tool_calling_method=tool_calling_method,
        mcp_json_file=mcp_json_file,
        mcp_server_config=mcp_server_config,
    ))
    webui_manager.add_components("agent_settings", tab_components)

    # === äº‹ä»¶ç»‘å®š ===
    # LLM Providerå˜åŒ–æ—¶æ›´æ–°Ollamaä¸Šä¸‹æ–‡é•¿åº¦å¯è§æ€§
    llm_provider.change(
        fn=lambda x: gr.update(visible=x == "ollama"),
        inputs=llm_provider,
        outputs=ollama_num_ctx
    )
    # LLM Providerå˜åŒ–æ—¶æ›´æ–°æ¨¡å‹ä¸‹æ‹‰åˆ—è¡¨
    llm_provider.change(
        lambda provider: update_model_dropdown(provider),
        inputs=[llm_provider],
        outputs=[llm_model_name]
    )
    
    # Planner LLM Providerå˜åŒ–æ—¶æ›´æ–°Ollamaä¸Šä¸‹æ–‡é•¿åº¦å¯è§æ€§
    planner_llm_provider.change(
        fn=lambda x: gr.update(visible=x == "ollama"),
        inputs=[planner_llm_provider],
        outputs=[planner_ollama_num_ctx]
    )
    # Planner LLM Providerå˜åŒ–æ—¶æ›´æ–°æ¨¡å‹ä¸‹æ‹‰åˆ—è¡¨
    planner_llm_provider.change(
        lambda provider: update_model_dropdown(provider),
        inputs=[planner_llm_provider],
        outputs=[planner_llm_model_name]
    )

    # MCPé…ç½®æ–‡ä»¶å˜åŒ–æ—¶æ›´æ–°é…ç½®æ˜¾ç¤º
    async def update_wrapper(mcp_file):
        """MCPé…ç½®æ›´æ–°åŒ…è£…å‡½æ•°"""
        update_dict = await update_mcp_server(mcp_file, webui_manager)
        yield update_dict

    mcp_json_file.change(
        update_wrapper,
        inputs=[mcp_json_file],
        outputs=[mcp_server_config, mcp_server_config]
    )
